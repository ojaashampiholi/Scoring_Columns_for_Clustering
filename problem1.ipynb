{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score to rank columns for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.linalg import orth\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding other features which do not contribute significantly to the data\n",
    "\n",
    "In order to create vectors which are not orthogonal to the already exixting vectors in any matrix, we can either take a scalar version of the vectors, linear combination of the vectors or vectors which are parallel to existing vectors. Here I have defined two function for scaling the vector and finding the linear combination of the vectors respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalingVector(A, P, S):\n",
    "    index = np.random.randint(0,S)\n",
    "    scaleBy = np.random.rand()\n",
    "    #print(index, scaleBy)\n",
    "    return scaleBy * A[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombination(A, P, S):\n",
    "    index1 = np.random.randint(0,S)\n",
    "    index2 = np.random.randint(0,S)\n",
    "    scaleBy1 = np.random.rand()\n",
    "    scaleBy2 = np.random.rand()\n",
    "    temp = (scaleBy1 * A[:,index1]) + (scaleBy2 * A[:,index2])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the data that is used to test the function\n",
    "\n",
    "First we define a matrix of size (N,S) which has all randomly initialised values. The next step is to convert the matrix such that all the S features are orthogonal to each other. \n",
    "In order to find the remaining (P-S) features, we randomly choose between either scaling the existing vectors or finding the linear combination of the two vectors. This is done using a randomly generated key. \n",
    "Once this is done, we can see that the function returns a matrix of size (N,P) which has S principle components (where S<P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrthogonalComponents(N, P, S, K):\n",
    "    initialMatrix = np.random.rand(N, S)\n",
    "    orthogonalisedMatrix = orth(initialMatrix)    \n",
    "    #print(orthogonalisedMatrix.shape)\n",
    "    \n",
    "    for i in range(P-S):\n",
    "        key = np.random.randint(0,2)\n",
    "        #print(key)\n",
    "        if key == 0:\n",
    "            temp = scalingVector(orthogonalisedMatrix, P, S)\n",
    "        else:\n",
    "            temp = linearCombination(orthogonalisedMatrix, P, S)\n",
    "\n",
    "        #temp = scalingVector(orthogonalisedMatrix, P, S)\n",
    "        temp = temp.reshape(N,1)\n",
    "        #print(temp)\n",
    "        #print(temp.shape)\n",
    "        orthogonalisedMatrix = np.append(orthogonalisedMatrix, temp,axis = 1)\n",
    "\n",
    "    return orthogonalisedMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the scores\n",
    "In order to get the scores from the data we apply Principal Component Analysis (PCA). PCA is used to find the features which contribute more to the data than all the other components. The Eigen Values that are obtained from PCA give us the measure of contributions that each feature has to the dataset. We use this value of Eigen Values as the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(x):\n",
    "    x -= np.mean(x, axis = 0)  \n",
    "    cov = np.cov(x, rowvar = False)\n",
    "    evals , evecs = np.linalg.eigh(cov)\n",
    "    idx = np.argsort(evals)[::-1]\n",
    "    evecs = evecs[:,idx]\n",
    "    evals = evals[idx]\n",
    "    #print(evals)\n",
    "    return evals, evecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out the functions on a smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for the features are\n",
      "[ 3.05791890e-03  3.55332336e-20 -4.88913348e-19]\n"
     ]
    }
   ],
   "source": [
    "N, P, S, K = 160, 3, 1, 3\n",
    "data = getOrthogonalComponents(N, P, S, K)\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=K, random_state=0).fit(data)\n",
    "scores, eigVectors = getScores(data)\n",
    "#print(eigValues)\n",
    "print(\"The scores for the features are\")\n",
    "print(np.real(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the functions on the parameters given in the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for the features are\n",
      "[ 2.36387825e-03  2.13617456e-03  1.57970356e-03  1.13805666e-03\n",
      "  1.10553318e-04  2.06271057e-19  1.19696898e-19  9.76121549e-20\n",
      " -2.64106480e-20 -1.29436426e-19]\n"
     ]
    }
   ],
   "source": [
    "# Defining the input parameters to be gven to the function\n",
    "N, P, S, K = 1000, 10, 5, 3\n",
    "\n",
    "# Generating the data from the function defined above:\n",
    "data = getOrthogonalComponents(N, P, S, K)\n",
    "\n",
    "# Finding the cluster sizes and centroids\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=K, random_state=0).fit(data)\n",
    "\n",
    "# Getting the scores using PCA (Principle Component Analysis)\n",
    "scores, eigVectors = getScores(data)\n",
    "print(\"The scores for the features are\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
